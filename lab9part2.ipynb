{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f7f8f4-d37f-4886-ad2f-9a1d9661bd1b",
   "metadata": {},
   "source": [
    "# Analyzing Data and Interpreting Images with OpenAI's o1 Reasoning Model vs. GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a830d-95fd-4bb0-8156-f4ce5ee41f95",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "OpenAI's o1 reasoning model is designed for complex problem-solving, data analysis, and image interpretation by simulating a multi-step thought process before generating responses. Unlike traditional GPT models, which produce output in a single pass, reasoning models use internal **reasoning tokens** to explore multiple approaches before finalizing an answer.\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://cdn.openai.com/API/images/guides/reasoning_tokens.png\" alt=\"Reasoning Tokens\" width=\"600\">\n",
    "</p>  \n",
    "\n",
    "*Source: [OpenAI Reasoning Models Guide](https://platform.openai.com/docs/guides/reasoning)*\n",
    "\n",
    "**Key Differences: o1 Reasoning Model vs. GPT**\n",
    "- Multi-step reasoning: o1 evaluates different solutions before selecting the best response.\n",
    "- Deeper analytical capabilities: Optimized for complex data interpretation tasks.\n",
    "- Context-aware image analysis: Provides more structured and insightful image descriptions.\n",
    "- Reasoning Effort Control: Users can adjust the depth of reasoning (`low`, `medium`, `high`).\n",
    "\n",
    "\n",
    "For more details, refer to the [OpenAI Reasoning Models Guide](https://platform.openai.com/docs/guides/reasoning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa19529-a6a5-486b-802e-ddfb39fb85f1",
   "metadata": {},
   "source": [
    "## Purchase and Store API Key\n",
    "\n",
    "You need to **purchase** your [OpenAI](https://openai.com/) API key and store it securely, such as in **AWS Secrets Manager**.\n",
    "\n",
    "- **Key Name:** `api_key`  \n",
    "- **Key Value:** `<your OpenAI API key>`  \n",
    "- **Secret Name:** `openai`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a126d9e-1487-4905-8cc0-5d55d1a06594",
   "metadata": {},
   "source": [
    "## Install Python Libraries\n",
    "\n",
    "- **openai**: Used to call `o1` and `GPT` models for data analysis and image interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f05dcb1-dab0-4a06-bf2b-c695a8d19d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca255da8-7177-49e6-bff7-27501305b4f6",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "The following libraries are used in this notebook:\n",
    "\n",
    "- **boto3**: AWS SDK for Python, used to interact with AWS services.\n",
    "- **json**: Standard Python library for handling JSON data.\n",
    "- **IPython.display**: Provides tools to display images, Markdown content, and other rich media in Jupyter Notebook.\n",
    "- **openai**: Used to call `o1` and `GPT` models for data analysis and image interpretation.\n",
    "- **pandas**: A powerful library for data manipulation and analysis.\n",
    "- **pprint**: Pretty prints data structures for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db0d630-749f-484e-8d01-79ec39e0e56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from IPython.display import display, Image, Markdown\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd547f9-8c03-4673-a194-e71e01b38a3d",
   "metadata": {},
   "source": [
    "## Retrieve API Keys Securely from AWS Secrets Manager\n",
    "\n",
    "The following function, `get_secret()`, retrieves a secret from **AWS Secrets Manager**. This is a secure way to store and access sensitive credentials, such as API keys, without hardcoding them into the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd3f543-0716-483c-88ce-b41f5fb418cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5711939-503e-44f6-bb28-0671c1131e26",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client\n",
    "\n",
    "The following code initializes the OpenAI client using a securely stored API key retrieved from AWS Secrets Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921be4e1-921f-4c84-b68d-fc72b435cc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= get_secret('openai')['api_key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860098d7-cfcc-4791-9b42-c526f8ff620a",
   "metadata": {},
   "source": [
    "## Load and Analyze the Diamonds Dataset\n",
    "\n",
    "This notebook uses the **diamonds dataset ([diamonds.csv](https://github.com/lbsocial/data-analysis-with-generative-ai/blob/main/diamonds.csv))**, which contains detailed attributes of diamonds, including weight, color, clarity, and price.\n",
    "\n",
    "One interesting pattern in the dataset is that **diamonds with \"IF\" (Internally Flawless) clarity tend to have the lowest average price** compared to other clarity grades. This observation is counterintuitive, as one might expect the highest-clarity diamonds to be the most expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebef8c09-e485-4bea-b86b-275cce615b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Use Case ID</th>\n",
       "      <th>AI Use Case Name</th>\n",
       "      <th>Agency With AI Use Case</th>\n",
       "      <th>Optional Note Field</th>\n",
       "      <th>Office With AI Use Case</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Current Stage Of Production</th>\n",
       "      <th>Lifecycle Stage Additional Comments</th>\n",
       "      <th>AI Techniques Used</th>\n",
       "      <th>Agency Training Used</th>\n",
       "      <th>...</th>\n",
       "      <th>Included In Enterprise Inventory</th>\n",
       "      <th>Public Data Link</th>\n",
       "      <th>Use Case Code Accessible</th>\n",
       "      <th>Code Included In Agency Inventory</th>\n",
       "      <th>Source Code Public Link</th>\n",
       "      <th>Agency Able To Test Code</th>\n",
       "      <th>Agency Able To Monitor/Audit</th>\n",
       "      <th>Name of Informational System</th>\n",
       "      <th>Withhold Use Case</th>\n",
       "      <th>Explanation To Withhold Use Case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>...</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Automated Delay detection using voice processing</td>\n",
       "      <td>Department of Transportation</td>\n",
       "      <td>Federal Aviation Administration</td>\n",
       "      <td>ATO</td>\n",
       "      <td>In order to get a full accounting of delay, au...</td>\n",
       "      <td>In production: less than 1 year</td>\n",
       "      <td>Initial development</td>\n",
       "      <td>Natural Language Processing;</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Wilbur</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>...</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>...</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>...</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>REDACTED</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Use Case ID                                  AI Use Case Name  \\\n",
       "0            3                                          REDACTED   \n",
       "1            4  Automated Delay detection using voice processing   \n",
       "2            5                                          REDACTED   \n",
       "3            6                                          REDACTED   \n",
       "4            7                                          REDACTED   \n",
       "\n",
       "        Agency With AI Use Case              Optional Note Field  \\\n",
       "0                      REDACTED                         REDACTED   \n",
       "1  Department of Transportation  Federal Aviation Administration   \n",
       "2                      REDACTED                         REDACTED   \n",
       "3                      REDACTED                         REDACTED   \n",
       "4                      REDACTED                         REDACTED   \n",
       "\n",
       "  Office With AI Use Case                                            Summary  \\\n",
       "0                REDACTED                                           REDACTED   \n",
       "1                     ATO  In order to get a full accounting of delay, au...   \n",
       "2                REDACTED                                           REDACTED   \n",
       "3                REDACTED                                           REDACTED   \n",
       "4                REDACTED                                           REDACTED   \n",
       "\n",
       "       Current Stage Of Production Lifecycle Stage Additional Comments  \\\n",
       "0                         REDACTED                            REDACTED   \n",
       "1  In production: less than 1 year                 Initial development   \n",
       "2                         REDACTED                            REDACTED   \n",
       "3                         REDACTED                            REDACTED   \n",
       "4                         REDACTED                            REDACTED   \n",
       "\n",
       "             AI Techniques Used Agency Training Used  ...  \\\n",
       "0                      REDACTED             REDACTED  ...   \n",
       "1  Natural Language Processing;                  Yes  ...   \n",
       "2                      REDACTED             REDACTED  ...   \n",
       "3                      REDACTED             REDACTED  ...   \n",
       "4                      REDACTED             REDACTED  ...   \n",
       "\n",
       "  Included In Enterprise Inventory Public Data Link Use Case Code Accessible  \\\n",
       "0                         REDACTED         REDACTED                 REDACTED   \n",
       "1                              Yes              NaN                      Yes   \n",
       "2                         REDACTED         REDACTED                 REDACTED   \n",
       "3                         REDACTED         REDACTED                 REDACTED   \n",
       "4                         REDACTED         REDACTED                 REDACTED   \n",
       "\n",
       "  Code Included In Agency Inventory Source Code Public Link  \\\n",
       "0                          REDACTED                REDACTED   \n",
       "1                               Yes                     NaN   \n",
       "2                          REDACTED                REDACTED   \n",
       "3                          REDACTED                REDACTED   \n",
       "4                          REDACTED                REDACTED   \n",
       "\n",
       "  Agency Able To Test Code Agency Able To Monitor/Audit  \\\n",
       "0                 REDACTED                     REDACTED   \n",
       "1                      Yes                          Yes   \n",
       "2                 REDACTED                     REDACTED   \n",
       "3                 REDACTED                     REDACTED   \n",
       "4                 REDACTED                     REDACTED   \n",
       "\n",
       "  Name of Informational System Withhold Use Case  \\\n",
       "0                     REDACTED              True   \n",
       "1                       Wilbur             False   \n",
       "2                     REDACTED              True   \n",
       "3                     REDACTED              True   \n",
       "4                     REDACTED              True   \n",
       "\n",
       "   Explanation To Withhold Use Case  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Department_of_Transportation_Inventory.csv')\n",
    "data_json = df.to_json(orient=\"records\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df8274-f532-4103-9b8a-a882aa23eb86",
   "metadata": {},
   "source": [
    "## Generate Data Analysis Prompt for OpenAI Model\n",
    "\n",
    "To investigate why diamonds with **IF (Internally Flawless) clarity** have the **lowest average price**, we generate a structured prompt for the OpenAI model. The model will analyze the dataset and generate insights, including **Python code for visualizations**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d7ac96-aef2-425c-91ae-6b004a3ccce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prompt = f\"Analyze the provided data from the Department of Transportation's Inventory of Artificial Intelligence Use Cases. Determine which AI use cases demonstrate the highest potential impact on improving transportation safety, efficiency, or infrastructure modernization. Identify any trends across different DOT agencies and provide Python-generated charts to support your conclusions. Data: {data_json}\"\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e269bba-2c1a-47e9-9662-3542873fa8ce",
   "metadata": {},
   "source": [
    "## Define a Function to Get Assistance from OpenAI GPT-4o\n",
    "\n",
    "The following function, `openai_gpt_help()`, sends a prompt to OpenAI's **GPT-4o model** and returns a response. It also prints the number of tokens used in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a02a837-a5c0-409e-92ce-7ae93e58c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_gpt_help(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        temperature = 0\n",
    "    )\n",
    "    token_usage = response.usage\n",
    "    \n",
    "    pprint(f\"Tokens used: {token_usage}\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df292b10-8857-4902-b2e4-8dab5602d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tokens used: CompletionUsage(completion_tokens=1126, prompt_tokens=7785, '\n",
      " 'total_tokens=8911, '\n",
      " 'completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, '\n",
      " 'audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), '\n",
      " 'prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))')\n"
     ]
    }
   ],
   "source": [
    "gpt_result = openai_gpt_help(prompt=data_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1360e35d-3dda-4447-8b5e-f58d16ad91d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To analyze the provided data from the Department of Transportation's Inventory of Artificial Intelligence Use Cases, we will focus on the use cases that are not redacted and assess their potential impact on improving transportation safety, efficiency, or infrastructure modernization. We will also identify trends across different DOT agencies and provide Python-generated charts to support our conclusions.\n",
       "\n",
       "### Analysis\n",
       "\n",
       "1. **Use Cases with Potential Impact:**\n",
       "   - **Automated Delay Detection using Voice Processing (Use Case ID: 4):**\n",
       "     - **Agency:** Federal Aviation Administration (FAA)\n",
       "     - **Impact:** This use case aims to improve the efficiency of air traffic management by automating the detection of delays through voice processing. This can lead to more accurate reporting and management of air traffic delays, enhancing overall efficiency.\n",
       "     - **AI Techniques:** Natural Language Processing (NLP)\n",
       "     - **Current Stage:** In production for less than 1 year\n",
       "\n",
       "   - **Surface Report Classifier (SCM/Auto-Class) (Use Case ID: 8):**\n",
       "     - **Agency:** FAA\n",
       "     - **Impact:** This use case focuses on classifying surface incident reports, which can significantly improve safety by identifying and categorizing runway incursions and excursions.\n",
       "     - **AI Techniques:** Support Vector Machines, Gradient Boosting, Neural Networks, NLP\n",
       "     - **Current Stage:** In production for more than 1 year\n",
       "\n",
       "   - **Offshore Precipitation Capability (OPC) (Use Case ID: 19):**\n",
       "     - **Agency:** FAA\n",
       "     - **Impact:** This use case enhances safety by providing accurate precipitation data, which is crucial for flight safety over oceanic and remote areas.\n",
       "     - **AI Techniques:** Convolutional Neural Network\n",
       "     - **Current Stage:** In production for more than 1 year\n",
       "\n",
       "   - **Machine Learning for Occupant Safety Research (Use Case ID: 27 & 28):**\n",
       "     - **Agency:** National Highway Traffic Safety Administration (NHTSA)\n",
       "     - **Impact:** These use cases aim to improve safety by predicting crash parameters and head kinematics, which are critical for understanding and mitigating injury risks in vehicle crashes.\n",
       "     - **AI Techniques:** Deep Learning Models, Convolutional Neural Networks, Long-Short Term Memory Networks\n",
       "     - **Current Stage:** Planned (not in production)\n",
       "\n",
       "2. **Trends Across DOT Agencies:**\n",
       "   - The FAA is actively using AI to enhance air traffic management and safety, with multiple use cases in production.\n",
       "   - The NHTSA is focusing on using AI for safety research, particularly in vehicle crash analysis.\n",
       "   - There is a strong emphasis on using NLP and machine learning techniques across various use cases.\n",
       "\n",
       "3. **Python-Generated Charts:**\n",
       "\n",
       "Let's generate some charts to visualize the distribution of AI techniques and the current stage of production for these use cases.\n",
       "\n",
       "```python\n",
       "import matplotlib.pyplot as plt\n",
       "import pandas as pd\n",
       "\n",
       "# Data for analysis\n",
       "data = [\n",
       "    {\"Use Case ID\": 4, \"AI Use Case Name\": \"Automated Delay detection using voice processing\", \"Agency\": \"FAA\", \"AI Techniques\": \"NLP\", \"Current Stage\": \"In production: less than 1 year\"},\n",
       "    {\"Use Case ID\": 8, \"AI Use Case Name\": \"Surface Report Classifiier (SCM/Auto-Class)\", \"Agency\": \"FAA\", \"AI Techniques\": \"SVM, Gradient Boosting, Neural Networks, NLP\", \"Current Stage\": \"In production: more than 1 year\"},\n",
       "    {\"Use Case ID\": 19, \"AI Use Case Name\": \"Offshore Precipitation Capability (OPC)\", \"Agency\": \"FAA\", \"AI Techniques\": \"Convolutional Neural Network\", \"Current Stage\": \"In production: more than 1 year\"},\n",
       "    {\"Use Case ID\": 27, \"AI Use Case Name\": \"Machine Learning for Occupant Safety Research\", \"Agency\": \"NHTSA\", \"AI Techniques\": \"Deep Learning, CNN, LSTM\", \"Current Stage\": \"Planned (not in production)\"},\n",
       "    {\"Use Case ID\": 28, \"AI Use Case Name\": \"Machine Learning for Occupant Safety Research\", \"Agency\": \"NHTSA\", \"AI Techniques\": \"Deep Learning, CNN\", \"Current Stage\": \"Planned (not in production)\"}\n",
       "]\n",
       "\n",
       "# Convert to DataFrame\n",
       "df = pd.DataFrame(data)\n",
       "\n",
       "# Plotting AI Techniques\n",
       "plt.figure(figsize=(10, 6))\n",
       "df['AI Techniques'].value_counts().plot(kind='bar', color='skyblue')\n",
       "plt.title('Distribution of AI Techniques')\n",
       "plt.xlabel('AI Techniques')\n",
       "plt.ylabel('Number of Use Cases')\n",
       "plt.xticks(rotation=45, ha='right')\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "\n",
       "# Plotting Current Stage of Production\n",
       "plt.figure(figsize=(10, 6))\n",
       "df['Current Stage'].value_counts().plot(kind='bar', color='lightgreen')\n",
       "plt.title('Current Stage of Production')\n",
       "plt.xlabel('Stage')\n",
       "plt.ylabel('Number of Use Cases')\n",
       "plt.xticks(rotation=45, ha='right')\n",
       "plt.tight_layout()\n",
       "plt.show()\n",
       "```\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The analysis shows that the FAA is leading in implementing AI use cases that are already in production, focusing on improving air traffic management and safety. The NHTSA is exploring AI for vehicle safety research, which is still in the planning stages. The use of NLP and machine learning techniques is prevalent across these use cases, indicating a trend towards leveraging these technologies for enhancing transportation safety and efficiency."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(gpt_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068efcc-c82a-40d8-8d5b-3939f2417a4e",
   "metadata": {},
   "source": [
    "## Define a Function to Get Assistance from OpenAI o1 Model  \n",
    "\n",
    "The following function, `openai_o_help()`, sends a prompt to OpenAI's **o1 reasoning model** and returns a response.  \n",
    "\n",
    "### Key Differences Between o1 and GPT Models:\n",
    "- **Reasoning Effort**: The o1 model allows users to control reasoning depth using `reasoning_effort` (`low`, `medium`, `high`).  \n",
    "- **No Temperature Parameter**: Unlike GPT models, **o1 does not support `temperature`**.  \n",
    "- **Developer Messages Replace System Messages**:  \n",
    "  - Starting with `o1-2024-12-17`, **developer messages** replace **system messages** to align with chain-of-command behavior.  \n",
    "\n",
    "### Best Practices for Prompting o1  \n",
    "- **Keep prompts simple and direct.**  \n",
    "- **Avoid chain-of-thought prompts.** o1 reasons internally, so step-by-step instructions aren't needed.  \n",
    "- **Use delimiters for clarity.** Use Markdown, XML tags, or section titles.  \n",
    "- **Try zero-shot first.** If needed, add few-shot examples that closely match your goal.  \n",
    "- **Be explicit.** Clearly define success criteria and constraints.  \n",
    "- **Markdown is disabled by default.** To enable, start with `\"Formatting re-enabled\"`.  \n",
    "\n",
    "Source: [OpenAI Reasoning Models Best Practices Guide](https://platform.openai.com/docs/guides/reasoning-best-practices).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f3d84b-b101-4299-b01a-ee4285c7608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_o_help(prompt):\n",
    "    messages = [ {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model='o1',\n",
    "        reasoning_effort=\"high\", # low, medium or high\n",
    "        messages=messages,\n",
    "\n",
    "    )\n",
    "    token_usage = response.usage\n",
    "    \n",
    "    pprint(f\"Tokens used: {token_usage}\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5fc9ef3-4510-4faf-995f-31a58134b9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tokens used: CompletionUsage(completion_tokens=6263, prompt_tokens=7784, '\n",
      " 'total_tokens=14047, '\n",
      " 'completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, '\n",
      " 'audio_tokens=0, reasoning_tokens=4160, rejected_prediction_tokens=0), '\n",
      " 'prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))')\n"
     ]
    }
   ],
   "source": [
    "o1_result = openai_o_help(prompt=data_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ab95a7-ee31-49c7-b2ad-f77996be5e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an analysis of the publicly listed AI use cases (i.e., those not marked “Withhold Use Case”) from the Department of Transportation’s Inventory of Artificial Intelligence Use Cases, highlighting which appear to have the greatest potential to improve safety, efficiency, or infrastructure modernization. Following the analysis, you will find example Python code snippets (using pandas and matplotlib) that illustrate how one might generate basic charts to support these conclusions.\n",
      "\n",
      "────────────────────────────────────────────────────────\n",
      "1) Identifying High-Impact AI Use Cases\n",
      "────────────────────────────────────────────────────────\n",
      "\n",
      "Note: Only use cases where \"Withhold Use Case\" = false are analyzed below. Many entries in the dataset are fully or partially redacted and marked to be withheld.\n",
      "\n",
      "Below is a short summary of the non-withheld use cases, grouped by their primary potential impact areas (safety, efficiency, and/or infrastructure modernization). Several use cases provide overlapping benefits in more than one category.\n",
      "\n",
      "A. Safety Improvements\n",
      "\n",
      "• Surface Report Classifier (Use Case ID 8, FAA/ATO)  \n",
      "  – In production >1 year.  \n",
      "  – Classifies surface incident reports (e.g., runway incursions) for improved safety monitoring.  \n",
      "  – High direct impact on aviation safety through better incident classification.\n",
      "\n",
      "• JASC Code Classification in Service Difficulty Reports (Use Case ID 17, FAA/AVS)  \n",
      "  – Planned.  \n",
      "  – Automates classification of safety difficulty reports, potentially improving maintenance oversight and safety trend detection.\n",
      "\n",
      "• Offshore Precipitation Capability (Use Case ID 19, FAA/NextGen)  \n",
      "  – In production >1 year.  \n",
      "  – Uses machine learning to improve the accuracy of oceanic precipitation depiction, enhancing pilot and controller awareness of hazardous weather.\n",
      "\n",
      "• Course Deviation Identification for Multiple Airport Route Separation (MARS) (Use Case ID 20, FAA/AVS)  \n",
      "  – Planned.  \n",
      "  – Applies machine learning to identify rare navigation errors (“course deviations”), helping validate reduced separation safety standards in busy airspace.\n",
      "\n",
      "• Determining Surface Winds with Machine Learning (Use Case ID 22, FAA/ANG)  \n",
      "  – Planned.  \n",
      "  – Uses camera images of windsocks to detect wind speed/direction in remote areas that lack sensors, improving safety at smaller or remote airports.\n",
      "\n",
      "• Remote Oceanic Meteorological Information Operations (ROMIO) (Use Case ID 23, FAA/ANG)  \n",
      "  – Planned.  \n",
      "  – Employs AI/ML on satellite, lightning, and weather model data to generate real-time thunderstorm activity and cloud heights for oceanic flights, enhancing safety.\n",
      "\n",
      "• Machine Learning for Occupant Safety Research (Use Case ID 27 & 28, NHTSA)  \n",
      "  – Planned.  \n",
      "  – Uses deep learning to predict crash parameters (head kinematics, Delta-V, direction of force), providing faster insight into injury potential and improving crash-safety analysis.\n",
      "\n",
      "B. Efficiency Gains\n",
      "\n",
      "• Automated Delay Detection Using Voice Processing (Use Case ID 4, FAA/ATO)  \n",
      "  – In production <1 year.  \n",
      "  – Transcribes/interprets air traffic voice data to identify unreported delays, potentially improving efficiency by capturing more accurate data about delays and vectoring events.\n",
      "\n",
      "• Course Deviation Identification (Use Case ID 20, FAA/AVS)  \n",
      "  – Also supports efficiency by safely allowing reduced separation standards in high-traffic metro areas.\n",
      "\n",
      "• PHMSA Rule Making (Use Case ID 29, PHMSA)  \n",
      "  – Planned.  \n",
      "  – Uses a Large Language Model to synthesize and categorize public comments in rulemaking. Streamlines the regulatory process, improving efficiency in reviewing large volumes of text.\n",
      "\n",
      "C. Infrastructure Modernization and Emerging Capabilities\n",
      "\n",
      "• Regulatory Compliance Mapping Tool (Use Case ID 16, FAA/AVS)  \n",
      "  – Planned.  \n",
      "  – Assists in mapping FAA Orders to ICAO Standards using NLP/recommender systems, helping modernize compliance workflows.\n",
      "\n",
      "• Path to Advanced Novel Data Analytics (PANDA) (Use Case ID 36, FHWA)  \n",
      "  – In production >1 year.  \n",
      "  – A data science lab at Turner-Fairbank Highway Research Center promoting AI/ML use across multiple highway disciplines, accelerating modernization in research practices.\n",
      "\n",
      "• PHMSA Rule Making (Use Case ID 29, PHMSA)  \n",
      "  – Also supports a more modern approach to rulemaking via LLM-based text analysis.\n",
      "\n",
      "────────────────────────────────────────────────────────\n",
      "2) Broad Observed Trends by Agency\n",
      "────────────────────────────────────────────────────────\n",
      "\n",
      "• Federal Aviation Administration (FAA).  \n",
      "  The FAA has the largest variety of non-withheld use cases. Many focus on improving aviation safety through:  \n",
      "  – Incident classification (Use Case IDs 8, 17),  \n",
      "  – Weather and wind detection (IDs 19, 22, 23),  \n",
      "  – Operational efficiency (IDs 4, 20).  \n",
      "  Natural Language Processing (NLP) and machine learning techniques (e.g., neural networks, boosting, support vector machines) are commonly used.\n",
      "\n",
      "• National Highway Traffic Safety Administration (NHTSA).  \n",
      "  Several occupant-safety research projects (IDs 27, 28) use deep learning to parse crash data and predict driver/passenger injury risks. This trend shows an emphasis on using cutting-edge AI for rapid crash analysis to improve highway safety.\n",
      "\n",
      "• Pipeline and Hazardous Materials Safety Administration (PHMSA).  \n",
      "  A generative Large Language Model (Use Case ID 29) is being piloted to modernize and expedite rulemaking by analyzing and summarizing public comments from Regulations.gov.\n",
      "\n",
      "• Federal Highway Administration (FHWA).  \n",
      "  The PANDA data science lab (ID 36) demonstrates a broad-based effort to integrate AI/ML into ongoing and future highway research, focusing on modernization and possibly cross-cutting safety and efficiency improvements.\n",
      "\n",
      "Overall, natural language processing (NLP), machine learning-based classification, and deep learning (including convolutional neural networks) dominate the techniques in use. Many of these projects aim to leverage data from either in-house (agency-generated) sources or publicly available transportation data (e.g., from Regulations.gov, crash databases, or meteorological data).\n",
      "\n",
      "────────────────────────────────────────────────────────\n",
      "3) Example Python Code for Basic Charts\n",
      "────────────────────────────────────────────────────────\n",
      "\n",
      "Below is a simplified code snippet that illustrates how one might:\n",
      "\n",
      "▪ Load the JSON data into a pandas DataFrame.  \n",
      "▪ Filter out withheld use cases.  \n",
      "▪ Create a couple of example charts showing (a) the distribution of AI use cases by agency, and (b) the stages of production for non-withheld use cases.\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Example JSON data (shortened for illustration). In practice, load the full data:\n",
      "data = [\n",
      "    {\n",
      "        \"Use Case ID\": 4,\n",
      "        \"AI Use Case Name\": \"Automated Delay detection using voice processing\",\n",
      "        \"Agency With AI Use Case\": \"Department of Transportation\",\n",
      "        \"Office With AI Use Case\": \"ATO\",\n",
      "        \"Current Stage Of Production\": \"In production: less than 1 year\",\n",
      "        \"Withhold Use Case\": False\n",
      "    },\n",
      "    {\n",
      "        \"Use Case ID\": 8,\n",
      "        \"AI Use Case Name\": \"Surface Report Classifiier (SCM/Auto-Class)\",\n",
      "        \"Agency With AI Use Case\": \"Department of Transportation\",\n",
      "        \"Office With AI Use Case\": \"ATO\",\n",
      "        \"Current Stage Of Production\": \"In production: more than 1 year\",\n",
      "        \"Withhold Use Case\": False\n",
      "    },\n",
      "    {\n",
      "        \"Use Case ID\": 27,\n",
      "        \"AI Use Case Name\": \"Machine Learning for Occupant Safety Research\",\n",
      "        \"Agency With AI Use Case\": \"National Highway Traffic Safety Administration\",\n",
      "        \"Office With AI Use Case\": \"NSR Human Injury Research Division\",\n",
      "        \"Current Stage Of Production\": \"Planned (not in production)\",\n",
      "        \"Withhold Use Case\": False\n",
      "    },\n",
      "    # ... additional non-withheld cases\n",
      "]\n",
      "\n",
      "# Load into a DataFrame\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Filter to only non-withheld use cases\n",
      "df_not_withheld = df[df[\"Withhold Use Case\"] == False].copy()\n",
      "\n",
      "# 1) Bar chart: Count of AI use cases by Agency\n",
      "agency_counts = df_not_withheld[\"Agency With AI Use Case\"].value_counts()\n",
      "\n",
      "plt.figure(figsize=(8, 4))\n",
      "agency_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
      "plt.title(\"Number of Non-Withheld AI Use Cases by Agency\")\n",
      "plt.xlabel(\"Agency\")\n",
      "plt.ylabel(\"Number of Use Cases\")\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# 2) Bar chart: Stages of Production distribution\n",
      "stage_counts = df_not_withheld[\"Current Stage Of Production\"].value_counts()\n",
      "\n",
      "plt.figure(figsize=(8, 4))\n",
      "stage_counts.plot(kind=\"bar\", color=\"green\")\n",
      "plt.title(\"Stages of Production (Non-Withheld Use Cases)\")\n",
      "plt.xlabel(\"Current Stage\")\n",
      "plt.ylabel(\"Count\")\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "4) Conclusions and Highlights\n",
      "\n",
      "Across the publicly disclosed use cases, several have clear potential to enhance transportation safety—especially those addressing runway incursions, weather detection, and crash analytics. Others aim to improve efficiency (e.g., automated detection of air traffic delays, advanced rulemaking processes) or modernize infrastructure (e.g., the FAA’s compliance mapping and FHWA’s PANDA data-science lab). Notable trends include:\n",
      "\n",
      "• Widespread use of NLP for text-heavy tasks (e.g., voice transcripts, regulatory compliance, classification of safety reports).  \n",
      "• Deep learning approaches, especially convolutional neural networks, for image tasks (weather depiction, crash image analysis).  \n",
      "• Growing interest in generative AI models (PHMSA’s rulemaking pilot).  \n",
      "• The FAA leading in AI efforts related to aviation safety and operations; NHTSA focusing on crash and injury analysis; FHWA establishing a central data-science hub; and PHMSA piloting advanced text analytics for policy.  \n",
      "\n",
      "Taken together, these projects reflect how AI is being strategically applied across the Department of Transportation to improve public safety, increase operational efficiency, and modernize regulatory processes.\n"
     ]
    }
   ],
   "source": [
    "print(o1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f151ea7-0d91-42f1-8c82-9c00d846e4be",
   "metadata": {},
   "source": [
    "1. How the model's reasoning supported your analysis: The model filtered the dataset to include only non-redacted use cases, allowing a focused analysis on transparent, operational AI applications. By identifying which agencies have the most visible AI deployments, the model used frequency analysis and data visualization to highlight where AI is actively improving transportation outcomes. This pattern supports the conclusion that certain agencies are more mature in their use of AI to enhance real-time responsiveness, a key factor in public service efficiency and safety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4170f1-cd0a-40a7-9a40-c3c3bee8d740",
   "metadata": {},
   "source": [
    "2. Whether this approach could be applied to real-world intelligence workflows: This approach closely mirrors workflows used in open-source intelligence (OSINT) and applied AI threat analysis. The process of filtering out redacted or classified content aligns with standard intelligence procedures for identifying actionable insights from open datasets. Analyzing trends such as counting the number of AI deployments by agency—helps prioritize resource allocation and supports risk assessments in national security contexts. Additionally, the use of Python-generated charts enhances the clarity of findings, enabling analysts to communicate trends effectively to policymakers and decision-makers. This analytical method could easily be repurposed to monitor AI developments in adversarial nations, evaluate emerging cyber threat landscapes, or assess the domestic policy impacts of new technologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84671191-a1c6-43ae-8c6d-0dd3ac1a7dde",
   "metadata": {},
   "source": [
    "3. Any limitations or ethical concerns you encountered: Several limitations and ethical concerns emerged in the analysis. Much of the dataset was redacted, limiting insight into AI use and strategy. Some use cases lacked detail, making it hard to assess performance or transparency. Ethically, the absence of oversight indicators and the use of AI in surveillance raise concerns about privacy and accountability. While withholding data may protect security, it also reduces public trust. These issues highlight the need for transparency and ethical oversight in government AI use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392719c-faa6-4438-a5ea-5e8e6d613d90",
   "metadata": {},
   "source": [
    "## References  \n",
    "- **OpenAI Reasoning Models Guide**: [OpenAI](https://platform.openai.com/docs/guides/reasoning)  \n",
    "- **OpenAI Reasoning Models Best Practices Guide**: [OpenAI](https://platform.openai.com/docs/guides/reasoning-best-practices)  \n",
    "- **Colin Jarvis. “Reasoning with O1.” DeepLearning.AI.** Accessed February 14, 2025. [DeepLearning.AI](https://www.deeplearning.ai/short-courses/reasoning-with-o1/)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
